{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f676104-a746-4caa-bce1-e7bdb226a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfe4470-2244-4a00-91bb-491436ed5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (from scikit-learn) (1.23.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83400597-2ce3-4387-b1ef-7f7b880b38a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\anaconda3\\envs\\gputest\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fbef58-5e29-4788-a16c-79c0eeed85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4149ae6-6b41-4d56-a268-a5e9dd30712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('resnet_simclr_checkpoint.pth')\n",
    "model_state_dict = checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448cd69d-38b5-4da2-9dff-214f1ac07968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet_model = models.resnet18(pretrained=False)  # Adjust model type if different\n",
    "resnet_model.fc = nn.Identity()\n",
    "\n",
    "# Load the model state\n",
    "resnet_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251723b8-e8b1-4e02-8023-ce7262671f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final layer: Identity()\n"
     ]
    }
   ],
   "source": [
    "print(\"Final layer:\", resnet_model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bff0bbd-c6cb-47f8-8714-eb3cb3f44ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize parameters for the linear layer\n",
    "num_features = 512  # This is typical for ResNet-18's final layer output\n",
    "num_classes = 10\n",
    "linear_layer = nn.Linear(num_features, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer for the linear layer\n",
    "optimizer = torch.optim.Adam(linear_layer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301f8d35-89b2-49f9-9ae7-a45a0ff8d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize parameters for the linear layer\n",
    "num_features = 512  # This is typical for ResNet-18's final layer output\n",
    "num_classes = 10\n",
    "linear_layer = nn.Linear(num_features, num_classes).to(device)\n",
    "\n",
    "# Optimizer for the linear layer\n",
    "optimizer = torch.optim.Adam(linear_layer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43ce493-3b59-4bac-b770-4ffffb2d8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_linear_classifier(features, linear_layer):\n",
    "    return linear_layer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13e62f1-443c-4a0e-89c7-6ed76e33ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "256aecf7-3eb8-4691-97ab-d4b5253a539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 2.0794 Acc: 22.93%\n",
      "Epoch [2/15] Loss: 2.0143 Acc: 25.55%\n",
      "Epoch [3/15] Loss: 2.0024 Acc: 26.17%\n",
      "Epoch [4/15] Loss: 1.9929 Acc: 26.69%\n",
      "Epoch [5/15] Loss: 1.9843 Acc: 26.88%\n",
      "Epoch [6/15] Loss: 1.9828 Acc: 27.45%\n",
      "Epoch [7/15] Loss: 1.9782 Acc: 27.36%\n",
      "Epoch [8/15] Loss: 1.9795 Acc: 27.12%\n",
      "Epoch [9/15] Loss: 1.9750 Acc: 27.24%\n",
      "Epoch [10/15] Loss: 1.9737 Acc: 27.47%\n",
      "Epoch [11/15] Loss: 1.9720 Acc: 27.92%\n",
      "Epoch [12/15] Loss: 1.9713 Acc: 27.69%\n",
      "Epoch [13/15] Loss: 1.9677 Acc: 28.14%\n",
      "Epoch [14/15] Loss: 1.9703 Acc: 27.78%\n",
      "Epoch [15/15] Loss: 1.9699 Acc: 27.79%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Assuming 'resnet_model' is your pre-trained ResNet model and it's already loaded\n",
    "        with torch.no_grad():\n",
    "            features = resnet_model(images)\n",
    "        \n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Apply linear classifier\n",
    "        outputs = apply_linear_classifier(features, linear_layer)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss / len(train_loader):.4f} Acc: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40b6806-1480-4fe0-b26c-bdbba04cb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_resnet_linear = {\n",
    "   'resnet_state_dict': resnet_model.state_dict(),\n",
    "   'linear_state_dict': linear_layer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint_resnet_linear, 'linear_resnet_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9244e41-fcb3-4703-9f2f-2b886f817b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('linear_resnet_classifier.pth', map_location=device)\n",
    "resnet_model.load_state_dict(checkpoint['resnet_state_dict'])\n",
    "linear_layer.load_state_dict(checkpoint['linear_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab47bcd-07f9-4cd6-8caa-1767c8224078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(images):\n",
    "    resnet_model.eval()\n",
    "    linear_layer.eval()\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(images)\n",
    "        outputs = linear_layer(features)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f44b0e49-a3e8-4205-8a26-b7a748715574",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3916f955-e20c-44af-915d-b0b71ff94b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Size of the test set: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_size = len(test_dataset)\n",
    "print(f\"Size of the test set: {test_size} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d51ed-a4f7-4a6a-a1f7-21b5776bbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = 0.0\n",
    "total_correct = 0\n",
    "total_images = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = forward_pass(images)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total_correct += (predicted == labels).sum().item()\n",
    "    total_images += labels.size(0)\n",
    "\n",
    "average_loss = running_loss / len(test_loader)\n",
    "accuracy = total_correct / total_images * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpu",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
